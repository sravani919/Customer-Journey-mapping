{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9a5d515-3720-4b30-894c-cd279e62bfd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.11/site-packages (4.46.3)\n",
      "Requirement already satisfied: accelerate in ./.local/lib/python3.11/site-packages (1.1.0)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in ./.local/lib/python3.11/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.11/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in ./.local/lib/python3.11/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.local/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: psutil in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./.local/lib/python3.11/site-packages (from accelerate) (2.5.1+cu121)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.local/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cc8d751-fac6-41a6-991a-7987da58329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_stage(row):\n",
    "    overlap = row[\"topics_overlap\"]\n",
    "    topic = row[\"topic_label\"]\n",
    "    sentiment = row[\"sentiment\"]\n",
    "    emotional_tone = row[\"final_consolidated_emotional_tone\"]\n",
    "\n",
    "    if overlap >= 0.2:\n",
    "        return \"Post-Purchase\"\n",
    "    if 0.1 <= overlap < 0.2:\n",
    "        if topic in [\"Connectivity & Portability\", \"Quality & Reviews\"]:\n",
    "            return \"Consideration\"\n",
    "        if topic in [\"Performance & Specifications\", \"Quality & Reviews\"]:\n",
    "            return \"Decision\"\n",
    "    if overlap < 0.1:\n",
    "        if topic in [\"Design & Usability\", \"Protection & Packaging\"]:\n",
    "            return \"Awareness\"\n",
    "        if topic in [\"Performance & Specifications\", \"Quality & Reviews\"]:\n",
    "            return \"Decision\"\n",
    "\n",
    "    if emotional_tone == \"Positive\" and sentiment == \"Positive\":\n",
    "        return \"Post-Purchase\"\n",
    "    elif emotional_tone == \"Neutral\" or sentiment == \"Neutral\":\n",
    "        return \"Consideration\"\n",
    "    elif emotional_tone == \"Negative\" or sentiment == \"Negative\":\n",
    "        return \"Decision\"\n",
    "    elif emotional_tone == \"Mixed\":\n",
    "        return \"Awareness\"\n",
    "\n",
    "    # Default fallback changed to \"Awareness\"\n",
    "    return \"Awareness\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a70cbdb3-152f-4623-8842-1f57c91f2649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_id                                      product_title  \\\n",
      "0  B07CZDXDG8  INIU Portable Charger, Slimmest 10000mAh 5V/3A...   \n",
      "1  B07CZDXDG8  INIU Portable Charger, Slimmest 10000mAh 5V/3A...   \n",
      "2  B07CZDXDG8  INIU Portable Charger, Slimmest 10000mAh 5V/3A...   \n",
      "3  B07CZDXDG8  INIU Portable Charger, Slimmest 10000mAh 5V/3A...   \n",
      "4  B07CZDXDG8  INIU Portable Charger, Slimmest 10000mAh 5V/3A...   \n",
      "\n",
      "                                 product_description product_price  \\\n",
      "0  From INIU--the SAFE Fast Charge Pro: Experienc...        $19.99   \n",
      "1  From INIU--the SAFE Fast Charge Pro: Experienc...        $19.99   \n",
      "2  From INIU--the SAFE Fast Charge Pro: Experienc...        $19.99   \n",
      "3  From INIU--the SAFE Fast Charge Pro: Experienc...        $19.99   \n",
      "4  From INIU--the SAFE Fast Charge Pro: Experienc...        $19.99   \n",
      "\n",
      "                                         product_url  \\\n",
      "0  https://www.amazon.com/INIU-High-Speed-Flashli...   \n",
      "1  https://www.amazon.com/INIU-High-Speed-Flashli...   \n",
      "2  https://www.amazon.com/INIU-High-Speed-Flashli...   \n",
      "3  https://www.amazon.com/INIU-High-Speed-Flashli...   \n",
      "4  https://www.amazon.com/INIU-High-Speed-Flashli...   \n",
      "\n",
      "                                          image_urls  \\\n",
      "0  ['https://m.media-amazon.com/images/I/516tnauV...   \n",
      "1  ['https://m.media-amazon.com/images/I/516tnauV...   \n",
      "2  ['https://m.media-amazon.com/images/I/516tnauV...   \n",
      "3  ['https://m.media-amazon.com/images/I/516tnauV...   \n",
      "4  ['https://m.media-amazon.com/images/I/516tnauV...   \n",
      "\n",
      "                                          video_urls         review_id  \\\n",
      "0  https://m.media-amazon.com/images/S/vse-vms-tr...  Product1_Review1   \n",
      "1  https://m.media-amazon.com/images/S/vse-vms-tr...  Product1_Review1   \n",
      "2  https://m.media-amazon.com/images/S/vse-vms-tr...  Product1_Review1   \n",
      "3  https://m.media-amazon.com/images/S/vse-vms-tr...  Product1_Review1   \n",
      "4  https://m.media-amazon.com/images/S/vse-vms-tr...  Product1_Review1   \n",
      "\n",
      "     timestamp embedding_type  ...  \\\n",
      "0  00:00-00:04         Visual  ...   \n",
      "1  00:00-00:04         Visual  ...   \n",
      "2  00:00-00:04         Visual  ...   \n",
      "3  00:00-00:04         Visual  ...   \n",
      "4  00:04-00:08           Text  ...   \n",
      "\n",
      "                           cleaned_key_topics_y_flat  \\\n",
      "0             Black Compact USBC Ports LED Indicator   \n",
      "1            USBC InOut Charging Speed Compatibility   \n",
      "2  3A HighSpeed Charging Fast Charging Charging Time   \n",
      "3     10000mAh Capacity Multiple Charges Portability   \n",
      "4             Black Compact USBC Ports LED Indicator   \n",
      "\n",
      "        grouped_key_topics_y grouped_emotional_tone  \\\n",
      "0  Portability Compatibility               Positive   \n",
      "1  Performance Compatibility               Positive   \n",
      "2                Performance               Positive   \n",
      "3                Portability               Positive   \n",
      "4  Portability Compatibility               Positive   \n",
      "\n",
      "                                     combined_topics  \\\n",
      "0  Product display Size Black Compact USB-C Ports...   \n",
      "1  Product display Size USB-C In/Out Charging Spe...   \n",
      "2  Product display Size 3A High-Speed Charging Fa...   \n",
      "3  Product display Size 10000mAh Capacity Multipl...   \n",
      "4  Great product INIU portable charger Black Comp...   \n",
      "\n",
      "                                      processed_text dominant_topic topic  \\\n",
      "0  product display size black compact usb-c port ...              1     2   \n",
      "1  product display size usb-c in/out charging spe...              1     1   \n",
      "2  product display size 3a high-speed charging fa...              1     1   \n",
      "3  product display size 10000mah capacity multipl...              1     2   \n",
      "4  great product iniu portable charger black comp...              1     2   \n",
      "\n",
      "  refined_consolidated_emotional_tone  final_consolidated_emotional_tone  \\\n",
      "0                            Positive                           Positive   \n",
      "1                            Positive                           Positive   \n",
      "2                            Positive                           Positive   \n",
      "3                            Positive                           Positive   \n",
      "4                            Positive                           Positive   \n",
      "\n",
      "                    topic_label  \n",
      "0  Performance & Specifications  \n",
      "1  Performance & Specifications  \n",
      "2  Performance & Specifications  \n",
      "3  Performance & Specifications  \n",
      "4  Performance & Specifications  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "Index(['product_id', 'product_title', 'product_description', 'product_price',\n",
      "       'product_url', 'image_urls', 'video_urls', 'review_id', 'timestamp',\n",
      "       'embedding_type', 'sentiment', 'key_topics_x', 'emotional_tone',\n",
      "       'customer_sentiment', 'image_id', 'focus', 'key_topics_y',\n",
      "       'description', 'topics_overlap', 'key_topics_y_str',\n",
      "       'key_topics_y_flat', 'key_topics_x_cleaned', 'cleaned_key_topics_x',\n",
      "       'grouped_key_topics_x', 'cleaned_key_topics_y_flat',\n",
      "       'grouped_key_topics_y', 'grouped_emotional_tone', 'combined_topics',\n",
      "       'processed_text', 'dominant_topic', 'topic',\n",
      "       'refined_consolidated_emotional_tone',\n",
      "       'final_consolidated_emotional_tone', 'topic_label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"dataset_with_topic_labels.csv\"  # Replace with the actual path to your dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic information\n",
    "print(df.head())  # Inspect the first few rows of the dataset\n",
    "print(df.columns)  # View column names to ensure all required columns exist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8ea9338-c9c4-498f-845b-3ebfc7c23ab5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_id                                      product_title  \\\n",
      "0  B07CZDXDG8  INIU Portable Charger, Slimmest 10000mAh 5V/3A...   \n",
      "1  B07CZDXDG8  INIU Portable Charger, Slimmest 10000mAh 5V/3A...   \n",
      "2  B07CZDXDG8  INIU Portable Charger, Slimmest 10000mAh 5V/3A...   \n",
      "3  B07CZDXDG8  INIU Portable Charger, Slimmest 10000mAh 5V/3A...   \n",
      "4  B07CZDXDG8  INIU Portable Charger, Slimmest 10000mAh 5V/3A...   \n",
      "\n",
      "                                 product_description product_price  \\\n",
      "0  From INIU--the SAFE Fast Charge Pro: Experienc...        $19.99   \n",
      "1  From INIU--the SAFE Fast Charge Pro: Experienc...        $19.99   \n",
      "2  From INIU--the SAFE Fast Charge Pro: Experienc...        $19.99   \n",
      "3  From INIU--the SAFE Fast Charge Pro: Experienc...        $19.99   \n",
      "4  From INIU--the SAFE Fast Charge Pro: Experienc...        $19.99   \n",
      "\n",
      "                                         product_url  \\\n",
      "0  https://www.amazon.com/INIU-High-Speed-Flashli...   \n",
      "1  https://www.amazon.com/INIU-High-Speed-Flashli...   \n",
      "2  https://www.amazon.com/INIU-High-Speed-Flashli...   \n",
      "3  https://www.amazon.com/INIU-High-Speed-Flashli...   \n",
      "4  https://www.amazon.com/INIU-High-Speed-Flashli...   \n",
      "\n",
      "                                          image_urls  \\\n",
      "0  ['https://m.media-amazon.com/images/I/516tnauV...   \n",
      "1  ['https://m.media-amazon.com/images/I/516tnauV...   \n",
      "2  ['https://m.media-amazon.com/images/I/516tnauV...   \n",
      "3  ['https://m.media-amazon.com/images/I/516tnauV...   \n",
      "4  ['https://m.media-amazon.com/images/I/516tnauV...   \n",
      "\n",
      "                                          video_urls         review_id  \\\n",
      "0  https://m.media-amazon.com/images/S/vse-vms-tr...  Product1_Review1   \n",
      "1  https://m.media-amazon.com/images/S/vse-vms-tr...  Product1_Review1   \n",
      "2  https://m.media-amazon.com/images/S/vse-vms-tr...  Product1_Review1   \n",
      "3  https://m.media-amazon.com/images/S/vse-vms-tr...  Product1_Review1   \n",
      "4  https://m.media-amazon.com/images/S/vse-vms-tr...  Product1_Review1   \n",
      "\n",
      "     timestamp embedding_type  ...       grouped_key_topics_y  \\\n",
      "0  00:00-00:04         Visual  ...  Portability Compatibility   \n",
      "1  00:00-00:04         Visual  ...  Performance Compatibility   \n",
      "2  00:00-00:04         Visual  ...                Performance   \n",
      "3  00:00-00:04         Visual  ...                Portability   \n",
      "4  00:04-00:08           Text  ...  Portability Compatibility   \n",
      "\n",
      "  grouped_emotional_tone                                    combined_topics  \\\n",
      "0               Positive  Product display Size Black Compact USB-C Ports...   \n",
      "1               Positive  Product display Size USB-C In/Out Charging Spe...   \n",
      "2               Positive  Product display Size 3A High-Speed Charging Fa...   \n",
      "3               Positive  Product display Size 10000mAh Capacity Multipl...   \n",
      "4               Positive  Great product INIU portable charger Black Comp...   \n",
      "\n",
      "                                      processed_text dominant_topic topic  \\\n",
      "0  product display size black compact usb-c port ...              1     2   \n",
      "1  product display size usb-c in/out charging spe...              1     1   \n",
      "2  product display size 3a high-speed charging fa...              1     1   \n",
      "3  product display size 10000mah capacity multipl...              1     2   \n",
      "4  great product iniu portable charger black comp...              1     2   \n",
      "\n",
      "  refined_consolidated_emotional_tone final_consolidated_emotional_tone  \\\n",
      "0                            Positive                          Positive   \n",
      "1                            Positive                          Positive   \n",
      "2                            Positive                          Positive   \n",
      "3                            Positive                          Positive   \n",
      "4                            Positive                          Positive   \n",
      "\n",
      "                    topic_label     stage  \n",
      "0  Performance & Specifications  Decision  \n",
      "1  Performance & Specifications  Decision  \n",
      "2  Performance & Specifications  Decision  \n",
      "3  Performance & Specifications  Decision  \n",
      "4  Performance & Specifications  Decision  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "Decision         367\n",
      "Awareness        279\n",
      "Post-Purchase    113\n",
      "Consideration     19\n",
      "Name: stage, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Apply the classification function to create a new column 'stage'\n",
    "df[\"stage\"] = df.apply(classify_stage, axis=1)\n",
    "\n",
    "# Display the updated dataframe and class distribution\n",
    "print(df.head())  # Inspect the first few rows to verify the 'stage' column\n",
    "print(df[\"stage\"].value_counts())  # View distribution of classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "150caded-b1a4-4987-92cc-912c49b6cc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 622\n",
      "Validation Samples: 156\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define input text and labels\n",
    "texts = df[\"processed_text\"]  # Ensure 'processed_text' contains your input text\n",
    "labels = df[\"stage\"]  # Target labels (stage)\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Print sample sizes\n",
    "print(f\"Training Samples: {len(train_texts)}\")\n",
    "print(f\"Validation Samples: {len(val_texts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5398109f-35ad-4341-bcd5-477d9a241be4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Map: {'Decision': 0, 'Post-Purchase': 1, 'Awareness': 2, 'Consideration': 3}\n"
     ]
    }
   ],
   "source": [
    "# Create label map\n",
    "label_map = {label: i for i, label in enumerate(df[\"stage\"].unique())}\n",
    "\n",
    "# Print the label map to verify\n",
    "print(\"Label Map:\", label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bad835a-097f-46be-beca-f3a3b280a02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24df336a56334da795285155b42160ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-3B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B\")\n",
    "\n",
    "# Add padding token if it's not present\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "# Load the model\n",
    "model_name = \"meta-llama/Llama-3.2-3B\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label_map))\n",
    "\n",
    "# Resize model embeddings for the updated tokenizer\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "model.gradient_checkpointing_enable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46042159-79f7-4fcd-9090-e650d8c63207",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_data(texts, labels, tokenizer, max_length=256):\n",
    "    tokenized = tokenizer(\n",
    "        list(texts),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    mapped_labels = [label_map[label] for label in labels]  # Map labels to integers\n",
    "    tokenized[\"labels\"] = torch.tensor(mapped_labels)  # Convert labels to tensor\n",
    "    return tokenized\n",
    "\n",
    "# Tokenize training and validation data\n",
    "train_encodings = tokenize_data(train_texts, train_labels, tokenizer)\n",
    "val_encodings = tokenize_data(val_texts, val_labels, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b8bad31-aa82-44fe-bc11-6bd35262fe48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Sample: {'input_ids': [128000, 55397, 22658, 2853, 53421, 304, 23960, 18991, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': 2}\n",
      "Validation Dataset Sample: {'input_ids': [128000, 9533, 18991, 1579, 51842, 1579, 22867, 2612, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': 2}\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Function to convert tokenized data to Hugging Face Dataset\n",
    "def create_hf_dataset(encodings):\n",
    "    dataset_dict = {key: encodings[key] for key in encodings if key != \"labels\"}\n",
    "    dataset_dict[\"labels\"] = encodings[\"labels\"]\n",
    "    return Dataset.from_dict(dataset_dict)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = create_hf_dataset(train_encodings)\n",
    "val_dataset = create_hf_dataset(val_encodings)\n",
    "\n",
    "# Verify the datasets\n",
    "print(\"Training Dataset Sample:\", train_dataset[0])\n",
    "print(\"Validation Dataset Sample:\", val_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12b3872a-9069-4897-a141-8d8f25cace11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: deepspeed in ./.local/lib/python3.11/site-packages (0.16.1)\n",
      "Requirement already satisfied: einops in ./.local/lib/python3.11/site-packages (from deepspeed) (0.8.0)\n",
      "Requirement already satisfied: hjson in ./.local/lib/python3.11/site-packages (from deepspeed) (3.1.0)\n",
      "Requirement already satisfied: msgpack in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from deepspeed) (1.0.3)\n",
      "Requirement already satisfied: ninja in ./.local/lib/python3.11/site-packages (from deepspeed) (1.11.1.2)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.11/site-packages (from deepspeed) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from deepspeed) (23.1)\n",
      "Requirement already satisfied: psutil in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from deepspeed) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from deepspeed) (8.0.0)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in ./.local/lib/python3.11/site-packages (from deepspeed) (2.9.2)\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.11/site-packages (from deepspeed) (2.5.1+cu121)\n",
      "Requirement already satisfied: tqdm in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from deepspeed) (4.65.0)\n",
      "Requirement already satisfied: nvidia-ml-py in ./.local/lib/python3.11/site-packages (from deepspeed) (12.560.30)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.local/lib/python3.11/site-packages (from pydantic>=2.0.0->deepspeed) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./.local/lib/python3.11/site-packages (from pydantic>=2.0.0->deepspeed) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./.local/lib/python3.11/site-packages (from pydantic>=2.0.0->deepspeed) (4.12.2)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.11/site-packages (from torch->deepspeed) (3.13.1)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.11/site-packages (from torch->deepspeed) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./.local/lib/python3.11/site-packages (from torch->deepspeed) (3.1.3)\n",
      "Requirement already satisfied: fsspec in ./.local/lib/python3.11/site-packages (from torch->deepspeed) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.local/lib/python3.11/site-packages (from torch->deepspeed) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.local/lib/python3.11/site-packages (from torch->deepspeed) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.local/lib/python3.11/site-packages (from torch->deepspeed) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.local/lib/python3.11/site-packages (from torch->deepspeed) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.local/lib/python3.11/site-packages (from torch->deepspeed) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.local/lib/python3.11/site-packages (from torch->deepspeed) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.local/lib/python3.11/site-packages (from torch->deepspeed) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.local/lib/python3.11/site-packages (from torch->deepspeed) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.local/lib/python3.11/site-packages (from torch->deepspeed) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.local/lib/python3.11/site-packages (from torch->deepspeed) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.local/lib/python3.11/site-packages (from torch->deepspeed) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in ./.local/lib/python3.11/site-packages (from torch->deepspeed) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.local/lib/python3.11/site-packages (from torch->deepspeed) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->deepspeed) (12.1.105)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.11/site-packages (from sympy==1.13.1->torch->deepspeed) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.local/lib/python3.11/site-packages (from jinja2->torch->deepspeed) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install deepspeed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c228ff0-100a-4e26-8571-99a11a70ed4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spati/.local/lib/python3.11/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=16,\n",
    "        evaluation_strategy='epoch',\n",
    "        save_strategy='no',\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        learning_rate=2e-5,\n",
    "        report_to=\"none\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b2866f8-465f-40ef-bb67-19a027834a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Device Name: NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"Device Name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feea7e7-6fc1-43e0-9ab2-1094085888a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "077935d5-509c-4df2-b7eb-1d5fc149c08b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Map: {'Decision': 0, 'Post-Purchase': 1, 'Awareness': 2, 'Consideration': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spati/.local/lib/python3.11/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/local_scratch/slurm.1337878/ipykernel_3464480/4117345177.py:111: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "ename": "MissingCUDAException",
     "evalue": "CUDA_HOME does not exist, unable to compile CUDA op(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingCUDAException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 111\u001b[0m\n\u001b[1;32m     97\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     98\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     99\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m     report_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m )\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Trainer\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    112\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    113\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m    114\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[1;32m    115\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mval_dataset,\n\u001b[1;32m    116\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m    117\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer\n\u001b[1;32m    118\u001b[0m )\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/utils/deprecation.py:165\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS):\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:585\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m    584\u001b[0m \u001b[38;5;66;03m# Just in case the model was wrapped outside of the `Trainer`\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m unwrapped_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39munwrap_model(model)\n\u001b[1;32m    586\u001b[0m model_forward \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    587\u001b[0m     unwrapped_model\u001b[38;5;241m.\u001b[39mforward\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_peft_model(unwrapped_model)\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m unwrapped_model\u001b[38;5;241m.\u001b[39mget_base_model()\u001b[38;5;241m.\u001b[39mforward\n\u001b[1;32m    590\u001b[0m )\n\u001b[1;32m    591\u001b[0m forward_params \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(model_forward)\u001b[38;5;241m.\u001b[39mparameters\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/accelerate/accelerator.py:2628\u001b[0m, in \u001b[0;36mAccelerator.unwrap_model\u001b[0;34m(self, model, keep_fp32_wrapper)\u001b[0m\n\u001b[1;32m   2597\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munwrap_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, keep_fp32_wrapper: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   2598\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2599\u001b[0m \u001b[38;5;124;03m    Unwraps the `model` from the additional layer possible added by [`~Accelerator.prepare`]. Useful before saving\u001b[39;00m\n\u001b[1;32m   2600\u001b[0m \u001b[38;5;124;03m    the model.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2626\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m   2627\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2628\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m extract_model_from_parallel(model, keep_fp32_wrapper)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/accelerate/utils/other.py:86\u001b[0m, in \u001b[0;36mextract_model_from_parallel\u001b[0;34m(model, keep_fp32_wrapper, recursive)\u001b[0m\n\u001b[1;32m     83\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_orig_mod\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_deepspeed_available():\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepspeed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeepSpeedEngine\n\u001b[1;32m     88\u001b[0m     options \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (DeepSpeedEngine,)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;124m\"\u001b[39m, FSDP_PYTORCH_VERSION) \u001b[38;5;129;01mand\u001b[39;00m is_torch_distributed_available():\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/deepspeed/__init__.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     HAS_TRITON \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_inject\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccelerator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_accelerator\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/deepspeed/ops/__init__.py:15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fp_quantizer\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeepSpeedTransformerLayer, DeepSpeedTransformerConfig\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgit_version_info\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compatible_ops \u001b[38;5;28;01mas\u001b[39;00m __compatible_ops__\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/deepspeed/git_version_info.py:29\u001b[0m\n\u001b[1;32m     27\u001b[0m compatible_ops \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mfromkeys(ALL_OPS\u001b[38;5;241m.\u001b[39mkeys(), \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m op_name, builder \u001b[38;5;129;01min\u001b[39;00m ALL_OPS\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 29\u001b[0m     op_compatible \u001b[38;5;241m=\u001b[39m builder\u001b[38;5;241m.\u001b[39mis_compatible()\n\u001b[1;32m     30\u001b[0m     compatible_ops[op_name] \u001b[38;5;241m=\u001b[39m op_compatible\n\u001b[1;32m     31\u001b[0m     compatible_ops[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepspeed_not_implemented\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/deepspeed/ops/op_builder/fp_quantizer.py:35\u001b[0m, in \u001b[0;36mFPQuantizerBuilder.is_compatible\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m     33\u001b[0m cuda_okay \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_rocm_pytorch() \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():  \u001b[38;5;66;03m#ignore-cuda\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     sys_cuda_major, _ \u001b[38;5;241m=\u001b[39m installed_cuda_version()\n\u001b[1;32m     36\u001b[0m     torch_cuda_major \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     37\u001b[0m     cuda_capability \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mget_device_properties(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mmajor  \u001b[38;5;66;03m#ignore-cuda\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/deepspeed/ops/op_builder/builder.py:51\u001b[0m, in \u001b[0;36minstalled_cuda_version\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     49\u001b[0m cuda_home \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcpp_extension\u001b[38;5;241m.\u001b[39mCUDA_HOME\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cuda_home \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingCUDAException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_HOME does not exist, unable to compile CUDA op(s)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Ensure there is not a cuda version mismatch between torch and nvcc compiler\u001b[39;00m\n\u001b[1;32m     53\u001b[0m output \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mcheck_output([cuda_home \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/bin/nvcc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-V\u001b[39m\u001b[38;5;124m\"\u001b[39m], universal_newlines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mMissingCUDAException\u001b[0m: CUDA_HOME does not exist, unable to compile CUDA op(s)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Ensure CUDA paths are set\n",
    "os.environ[\"CUDA_HOME\"] = \"/usr/local/cuda-12.3\"\n",
    "os.environ[\"PATH\"] = f\"{os.environ['CUDA_HOME']}/bin:{os.environ['PATH']}\"\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = f\"{os.environ['CUDA_HOME']}/lib64:{os.environ.get('LD_LIBRARY_PATH', '')}\"\n",
    "\n",
    "# Verify CUDA availability\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"Device Name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"meta-llama/Llama-3.2-3B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4)\n",
    "\n",
    "# Tokenizer update for padding\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    fp16=True,  # Enable mixed precision\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"  # Avoid external logging\n",
    ")\n",
    "\n",
    "# Dummy datasets (replace with actual datasets)\n",
    "from datasets import Dataset\n",
    "data = {\"input_ids\": [[1, 2, 3], [4, 5, 6]], \"labels\": [0, 1]}\n",
    "train_dataset = Dataset.from_dict(data)\n",
    "eval_dataset = Dataset.from_dict(data)\n",
    "\n",
    "# Define compute metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    preds = predictions.argmax(axis=1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    precision = precision_score(labels, preds, average=\"weighted\")\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")\n",
    "    return {\"accuracy\": accuracy, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train and Evaluate\n",
    "trainer.train()\n",
    "results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea11cbb3-4737-49b5-8602-68afd4608e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb496310-9ec0-4d45-abb3-1fc5daee084c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28ba0b6-b7e5-40f2-be0c-7696a953350b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3219fe8-6868-405a-980f-b6e9c6d71306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6dbcd3-2d95-4aa6-afbd-016c5364c29b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62441485-507f-4bfd-81e5-c21991beb0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
