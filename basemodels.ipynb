{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fa8bf7a-75c2-4c6c-ab9e-d4d92b6b6add",
   "metadata": {},
   "source": [
    "bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e04929fd-8f1d-4980-bbed-95dcf048a3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Map: {'Decision': 0, 'Post-Purchase': 1, 'Awareness': 2, 'Consideration': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/spati/.local/lib/python3.11/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/local_scratch/slurm.1341530/ipykernel_2965522/1175722462.py:102: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='117' max='117' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [117/117 04:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.730952</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.688025</td>\n",
       "      <td>0.626233</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.539022</td>\n",
       "      <td>0.801282</td>\n",
       "      <td>0.738543</td>\n",
       "      <td>0.780596</td>\n",
       "      <td>0.801282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.496934</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.795813</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics: {'eval_loss': 0.4969337582588196, 'eval_accuracy': 0.8333333333333334, 'eval_f1': 0.7958129611355418, 'eval_precision': 0.8169008929878495, 'eval_recall': 0.8333333333333334, 'eval_runtime': 4.0235, 'eval_samples_per_second': 38.773, 'eval_steps_per_second': 1.243, 'epoch': 3.0}\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Decision       0.88      0.97      0.93        70\n",
      "Post-Purchase       0.78      0.25      0.38        28\n",
      "    Awareness       0.80      1.00      0.89        55\n",
      "Consideration       0.00      0.00      0.00         3\n",
      "\n",
      "     accuracy                           0.83       156\n",
      "    macro avg       0.61      0.56      0.55       156\n",
      " weighted avg       0.82      0.83      0.80       156\n",
      "\n",
      "\n",
      "Metrics for 'Awareness':\n",
      "Total 'Awareness' Samples: 55\n",
      "Correct 'Awareness' Predictions: 55\n",
      "Precision: 0.80\n",
      "Recall: 1.00\n",
      "Accuracy: 0.35\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Disable DeepSpeed and CUDA if necessary\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"  # Force CPU if needed\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"dataset_with_topic_labels.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "def classify_stage(row):\n",
    "    overlap = row[\"topics_overlap\"]\n",
    "    topic = row[\"topic_label\"]\n",
    "    sentiment = row[\"sentiment\"]\n",
    "    emotional_tone = row[\"final_consolidated_emotional_tone\"]\n",
    "\n",
    "    if overlap >= 0.2:\n",
    "        return \"Post-Purchase\"\n",
    "    if 0.1 <= overlap < 0.2:\n",
    "        if topic in [\"Connectivity & Portability\", \"Quality & Reviews\"]:\n",
    "            return \"Consideration\"\n",
    "        if topic in [\"Performance & Specifications\", \"Quality & Reviews\"]:\n",
    "            return \"Decision\"\n",
    "    if overlap < 0.1:\n",
    "        if topic in [\"Design & Usability\", \"Protection & Packaging\"]:\n",
    "            return \"Awareness\"\n",
    "        if topic in [\"Performance & Specifications\", \"Quality & Reviews\"]:\n",
    "            return \"Decision\"\n",
    "\n",
    "    if emotional_tone == \"Positive\" and sentiment == \"Positive\":\n",
    "        return \"Post-Purchase\"\n",
    "    elif emotional_tone == \"Neutral\" or sentiment == \"Neutral\":\n",
    "        return \"Consideration\"\n",
    "    elif emotional_tone == \"Negative\" or sentiment == \"Negative\":\n",
    "        return \"Decision\"\n",
    "    elif emotional_tone == \"Mixed\":\n",
    "        return \"Awareness\"\n",
    "\n",
    "    return \"Awareness\"\n",
    "\n",
    "# Apply classify_stage\n",
    "df[\"stage\"] = df.apply(classify_stage, axis=1)\n",
    "\n",
    "# Create label map\n",
    "label_map = {label: i for i, label in enumerate(df[\"stage\"].unique())}\n",
    "print(\"Label Map:\", label_map)\n",
    "\n",
    "# Define custom dataset\n",
    "class CommentsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.encodings = tokenizer(list(texts), truncation=True, padding=True, max_length=max_length)\n",
    "        self.labels = [label_map[label] for label in labels]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"processed_text\"], df[\"stage\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label_map))\n",
    "\n",
    "train_dataset = CommentsDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = CommentsDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"weighted\"),\n",
    "        \"precision\": precision_score(labels, preds, average=\"weighted\"),\n",
    "        \"recall\": recall_score(labels, preds, average=\"weighted\"),\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    logging_dir=\"./logs\",\n",
    "    learning_rate=2e-5,\n",
    "    fp16=False,  # Avoid mixed precision\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Train\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate\n",
    "metrics = trainer.evaluate()\n",
    "print(\"Evaluation Metrics:\", metrics)\n",
    "\n",
    "# Extract true and predicted labels\n",
    "predictions, labels, _ = trainer.predict(val_dataset)\n",
    "y_pred = predictions.argmax(-1)\n",
    "y_true = labels\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=label_map.keys()))\n",
    "\n",
    "# Calculate metrics for \"Awareness\"\n",
    "awareness_label = label_map[\"Awareness\"]\n",
    "\n",
    "# Total number of true \"Awareness\" samples\n",
    "total_awareness = sum(y_true == awareness_label)\n",
    "\n",
    "# Number of correct \"Awareness\" predictions\n",
    "correct_awareness = sum((y_true == awareness_label) & (y_pred == awareness_label))\n",
    "\n",
    "# Calculate precision, recall, and accuracy for \"Awareness\"\n",
    "precision_awareness = correct_awareness / sum(y_pred == awareness_label) if sum(y_pred == awareness_label) > 0 else 0\n",
    "recall_awareness = correct_awareness / total_awareness if total_awareness > 0 else 0\n",
    "accuracy_awareness = correct_awareness / len(y_true)\n",
    "\n",
    "print(f\"\\nMetrics for 'Awareness':\")\n",
    "print(f\"Total 'Awareness' Samples: {total_awareness}\")\n",
    "print(f\"Correct 'Awareness' Predictions: {correct_awareness}\")\n",
    "print(f\"Precision: {precision_awareness:.2f}\")\n",
    "print(f\"Recall: {recall_awareness:.2f}\")\n",
    "print(f\"Accuracy: {accuracy_awareness:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f875af-90cb-4447-9bad-151d4abcd0cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "Roberta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c41b44dd-e163-4489-a8a2-34ff4c7ce895",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Map: {'Decision': 0, 'Post-Purchase': 1, 'Awareness': 2, 'Consideration': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/spati/.local/lib/python3.11/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/local_scratch/slurm.1341530/ipykernel_2965522/156526530.py:100: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='117' max='117' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [117/117 04:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.606414</td>\n",
       "      <td>0.775641</td>\n",
       "      <td>0.694812</td>\n",
       "      <td>0.635058</td>\n",
       "      <td>0.775641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.483426</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.793005</td>\n",
       "      <td>0.802831</td>\n",
       "      <td>0.826923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.465179</td>\n",
       "      <td>0.852564</td>\n",
       "      <td>0.829585</td>\n",
       "      <td>0.827080</td>\n",
       "      <td>0.852564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics: {'eval_loss': 0.465178519487381, 'eval_accuracy': 0.8525641025641025, 'eval_f1': 0.8295851722141933, 'eval_precision': 0.8270800410767208, 'eval_recall': 0.8525641025641025, 'eval_runtime': 3.8464, 'eval_samples_per_second': 40.558, 'eval_steps_per_second': 1.3, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Decision       0.87      0.99      0.93        70\n",
      "Post-Purchase       0.75      0.43      0.55        28\n",
      "    Awareness       0.85      0.95      0.90        55\n",
      "Consideration       0.00      0.00      0.00         3\n",
      "\n",
      "     accuracy                           0.85       156\n",
      "    macro avg       0.62      0.59      0.59       156\n",
      " weighted avg       0.83      0.85      0.83       156\n",
      "\n",
      "\n",
      "Metrics for 'Awareness':\n",
      "Total 'Awareness' Samples: 55\n",
      "Correct 'Awareness' Predictions: 52\n",
      "Precision: 0.85\n",
      "Recall: 0.95\n",
      "Accuracy: 0.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, classification_report\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"dataset_with_topic_labels.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "def classify_stage(row):\n",
    "    overlap = row[\"topics_overlap\"]\n",
    "    topic = row[\"topic_label\"]\n",
    "    sentiment = row[\"sentiment\"]\n",
    "    emotional_tone = row[\"final_consolidated_emotional_tone\"]\n",
    "\n",
    "    if overlap >= 0.2:\n",
    "        return \"Post-Purchase\"\n",
    "    if 0.1 <= overlap < 0.2:\n",
    "        if topic in [\"Connectivity & Portability\", \"Quality & Reviews\"]:\n",
    "            return \"Consideration\"\n",
    "        if topic in [\"Performance & Specifications\", \"Quality & Reviews\"]:\n",
    "            return \"Decision\"\n",
    "    if overlap < 0.1:\n",
    "        if topic in [\"Design & Usability\", \"Protection & Packaging\"]:\n",
    "            return \"Awareness\"\n",
    "        if topic in [\"Performance & Specifications\", \"Quality & Reviews\"]:\n",
    "            return \"Decision\"\n",
    "\n",
    "    if emotional_tone == \"Positive\" and sentiment == \"Positive\":\n",
    "        return \"Post-Purchase\"\n",
    "    elif emotional_tone == \"Neutral\" or sentiment == \"Neutral\":\n",
    "        return \"Consideration\"\n",
    "    elif emotional_tone == \"Negative\" or sentiment == \"Negative\":\n",
    "        return \"Decision\"\n",
    "    elif emotional_tone == \"Mixed\":\n",
    "        return \"Awareness\"\n",
    "\n",
    "    return \"Awareness\"\n",
    "\n",
    "# Apply classify_stage\n",
    "df[\"stage\"] = df.apply(classify_stage, axis=1)\n",
    "\n",
    "# Create label map\n",
    "label_map = {label: i for i, label in enumerate(df[\"stage\"].unique())}\n",
    "print(\"Label Map:\", label_map)\n",
    "\n",
    "# Define custom dataset\n",
    "class CommentsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.encodings = tokenizer(list(texts), truncation=True, padding=True, max_length=max_length)\n",
    "        self.labels = [label_map[label] for label in labels]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"processed_text\"], df[\"stage\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Switch to RoBERTa model\n",
    "model_name = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label_map))\n",
    "\n",
    "train_dataset = CommentsDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = CommentsDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"weighted\"),\n",
    "        \"precision\": precision_score(labels, preds, average=\"weighted\"),\n",
    "        \"recall\": recall_score(labels, preds, average=\"weighted\"),\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    logging_dir=\"./logs\",\n",
    "    learning_rate=2e-5,\n",
    "    fp16=False,  # Avoid mixed precision\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Train\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate\n",
    "metrics = trainer.evaluate()\n",
    "print(\"Evaluation Metrics:\", metrics)\n",
    "\n",
    "# Extract true and predicted labels\n",
    "predictions, labels, _ = trainer.predict(val_dataset)\n",
    "y_pred = predictions.argmax(-1)\n",
    "y_true = labels\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=label_map.keys()))\n",
    "\n",
    "# Calculate metrics for \"Awareness\"\n",
    "awareness_label = label_map[\"Awareness\"]\n",
    "\n",
    "# Total number of true \"Awareness\" samples\n",
    "total_awareness = sum(y_true == awareness_label)\n",
    "\n",
    "# Number of correct \"Awareness\" predictions\n",
    "correct_awareness = sum((y_true == awareness_label) & (y_pred == awareness_label))\n",
    "\n",
    "# Calculate precision, recall, and accuracy for \"Awareness\"\n",
    "precision_awareness = correct_awareness / sum(y_pred == awareness_label) if sum(y_pred == awareness_label) > 0 else 0\n",
    "recall_awareness = correct_awareness / total_awareness if total_awareness > 0 else 0\n",
    "accuracy_awareness = correct_awareness / len(y_true)\n",
    "\n",
    "print(f\"\\nMetrics for 'Awareness':\")\n",
    "print(f\"Total 'Awareness' Samples: {total_awareness}\")\n",
    "print(f\"Correct 'Awareness' Predictions: {correct_awareness}\")\n",
    "print(f\"Precision: {precision_awareness:.2f}\")\n",
    "print(f\"Recall: {recall_awareness:.2f}\")\n",
    "print(f\"Accuracy: {accuracy_awareness:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b89c5775-7733-461b-a7b4-9f951a7facd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Map: {'Decision': 0, 'Post-Purchase': 1, 'Awareness': 2, 'Consideration': 3}\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Decision       0.94      0.97      0.96        70\n",
      "Post-Purchase       0.85      0.61      0.71        28\n",
      "    Awareness       0.92      1.00      0.96        55\n",
      "Consideration       0.25      0.33      0.29         3\n",
      "\n",
      "     accuracy                           0.90       156\n",
      "    macro avg       0.74      0.73      0.73       156\n",
      " weighted avg       0.90      0.90      0.90       156\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[68  1  1  0]\n",
      " [ 4 17  4  3]\n",
      " [ 0  0 55  0]\n",
      " [ 0  2  0  1]]\n",
      "\n",
      "Overall Metrics:\n",
      "Accuracy: 0.90\n",
      "Precision: 0.90\n",
      "Recall: 0.90\n",
      "F1-Score: 0.90\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"dataset_with_topic_labels.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Classification logic\n",
    "def classify_stage(row):\n",
    "    overlap = row[\"topics_overlap\"]\n",
    "    topic = row[\"topic_label\"]\n",
    "    sentiment = row[\"sentiment\"]\n",
    "    emotional_tone = row[\"final_consolidated_emotional_tone\"]\n",
    "\n",
    "    if overlap >= 0.2:\n",
    "        return \"Post-Purchase\"\n",
    "    if 0.1 <= overlap < 0.2:\n",
    "        if topic in [\"Connectivity & Portability\", \"Quality & Reviews\"]:\n",
    "            return \"Consideration\"\n",
    "        if topic in [\"Performance & Specifications\", \"Quality & Reviews\"]:\n",
    "            return \"Decision\"\n",
    "    if overlap < 0.1:\n",
    "        if topic in [\"Design & Usability\", \"Protection & Packaging\"]:\n",
    "            return \"Awareness\"\n",
    "        if topic in [\"Performance & Specifications\", \"Quality & Reviews\"]:\n",
    "            return \"Decision\"\n",
    "\n",
    "    if emotional_tone == \"Positive\" and sentiment == \"Positive\":\n",
    "        return \"Post-Purchase\"\n",
    "    elif emotional_tone == \"Neutral\" or sentiment == \"Neutral\":\n",
    "        return \"Consideration\"\n",
    "    elif emotional_tone == \"Negative\" or sentiment == \"Negative\":\n",
    "        return \"Decision\"\n",
    "    elif emotional_tone == \"Mixed\":\n",
    "        return \"Awareness\"\n",
    "\n",
    "    return \"Awareness\"\n",
    "\n",
    "# Apply classify_stage\n",
    "df[\"stage\"] = df.apply(classify_stage, axis=1)\n",
    "\n",
    "# Create label map\n",
    "label_map = {label: i for i, label in enumerate(df[\"stage\"].unique())}\n",
    "print(\"Label Map:\", label_map)\n",
    "\n",
    "# Convert labels to numeric\n",
    "df[\"stage_label\"] = df[\"stage\"].map(label_map)\n",
    "\n",
    "# Split data\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"processed_text\"], df[\"stage_label\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Text vectorization using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(train_texts)\n",
    "X_val = vectorizer.transform(val_texts)\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, train_labels)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_val)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(val_labels, y_pred, target_names=label_map.keys()))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(val_labels, y_pred))\n",
    "\n",
    "# Overall metrics\n",
    "overall_accuracy = accuracy_score(val_labels, y_pred)\n",
    "overall_precision = precision_score(val_labels, y_pred, average=\"weighted\")\n",
    "overall_recall = recall_score(val_labels, y_pred, average=\"weighted\")\n",
    "overall_f1 = f1_score(val_labels, y_pred, average=\"weighted\")\n",
    "\n",
    "print(\"\\nOverall Metrics:\")\n",
    "print(f\"Accuracy: {overall_accuracy:.2f}\")\n",
    "print(f\"Precision: {overall_precision:.2f}\")\n",
    "print(f\"Recall: {overall_recall:.2f}\")\n",
    "print(f\"F1-Score: {overall_f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6de0ef9-f615-47cf-be8e-ef175fe6bb84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Map: {'Decision': 0, 'Post-Purchase': 1, 'Awareness': 2, 'Consideration': 3}\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Decision       0.93      0.97      0.95        70\n",
      "Post-Purchase       0.72      0.46      0.57        28\n",
      "    Awareness       0.83      0.98      0.90        55\n",
      "Consideration       0.00      0.00      0.00         3\n",
      "\n",
      "     accuracy                           0.87       156\n",
      "    macro avg       0.62      0.60      0.60       156\n",
      " weighted avg       0.84      0.87      0.85       156\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[68  1  1  0]\n",
      " [ 5 13 10  0]\n",
      " [ 0  1 54  0]\n",
      " [ 0  3  0  0]]\n",
      "\n",
      "Overall Metrics:\n",
      "Accuracy: 0.87\n",
      "Precision: 0.84\n",
      "Recall: 0.87\n",
      "F1-Score: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"dataset_with_topic_labels.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Classification logic\n",
    "def classify_stage(row):\n",
    "    overlap = row[\"topics_overlap\"]\n",
    "    topic = row[\"topic_label\"]\n",
    "    sentiment = row[\"sentiment\"]\n",
    "    emotional_tone = row[\"final_consolidated_emotional_tone\"]\n",
    "\n",
    "    if overlap >= 0.2:\n",
    "        return \"Post-Purchase\"\n",
    "    if 0.1 <= overlap < 0.2:\n",
    "        if topic in [\"Connectivity & Portability\", \"Quality & Reviews\"]:\n",
    "            return \"Consideration\"\n",
    "        if topic in [\"Performance & Specifications\", \"Quality & Reviews\"]:\n",
    "            return \"Decision\"\n",
    "    if overlap < 0.1:\n",
    "        if topic in [\"Design & Usability\", \"Protection & Packaging\"]:\n",
    "            return \"Awareness\"\n",
    "        if topic in [\"Performance & Specifications\", \"Quality & Reviews\"]:\n",
    "            return \"Decision\"\n",
    "\n",
    "    if emotional_tone == \"Positive\" and sentiment == \"Positive\":\n",
    "        return \"Post-Purchase\"\n",
    "    elif emotional_tone == \"Neutral\" or sentiment == \"Neutral\":\n",
    "        return \"Consideration\"\n",
    "    elif emotional_tone == \"Negative\" or sentiment == \"Negative\":\n",
    "        return \"Decision\"\n",
    "    elif emotional_tone == \"Mixed\":\n",
    "        return \"Awareness\"\n",
    "\n",
    "    return \"Awareness\"\n",
    "\n",
    "# Apply classify_stage\n",
    "df[\"stage\"] = df.apply(classify_stage, axis=1)\n",
    "\n",
    "# Create label map\n",
    "label_map = {label: i for i, label in enumerate(df[\"stage\"].unique())}\n",
    "print(\"Label Map:\", label_map)\n",
    "\n",
    "# Convert labels to numeric\n",
    "df[\"stage_label\"] = df[\"stage\"].map(label_map)\n",
    "\n",
    "# Split data\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"processed_text\"], df[\"stage_label\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Text vectorization using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(train_texts)\n",
    "X_val = vectorizer.transform(val_texts)\n",
    "\n",
    "# Train SVM Classifier\n",
    "svm_model = SVC(kernel=\"linear\", probability=True, random_state=42)\n",
    "svm_model.fit(X_train, train_labels)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svm_model.predict(X_val)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(val_labels, y_pred, target_names=label_map.keys()))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(val_labels, y_pred))\n",
    "\n",
    "# Overall metrics\n",
    "overall_accuracy = accuracy_score(val_labels, y_pred)\n",
    "overall_precision = precision_score(val_labels, y_pred, average=\"weighted\")\n",
    "overall_recall = recall_score(val_labels, y_pred, average=\"weighted\")\n",
    "overall_f1 = f1_score(val_labels, y_pred, average=\"weighted\")\n",
    "\n",
    "print(\"\\nOverall Metrics:\")\n",
    "print(f\"Accuracy: {overall_accuracy:.2f}\")\n",
    "print(f\"Precision: {overall_precision:.2f}\")\n",
    "print(f\"Recall: {overall_recall:.2f}\")\n",
    "print(f\"F1-Score: {overall_f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd80d20-55b8-4682-b202-8294be8a8f91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Label Map: {'Decision': 0, 'Post-Purchase': 1, 'Awareness': 2, 'Consideration': 3}\n",
      "Added padding token '[PAD]' to tokenizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f439473ba12e483c8a9dd998cb6b0818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-3B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/home/spati/.local/lib/python3.11/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/local_scratch/slurm.1341530/ipykernel_2965522/1866427360.py:136: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='105' max='1866' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 105/1866 1:14:37 < 21:15:58, 0.02 it/s, Epoch 0.17/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensure correct device usage\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"dataset_with_topic_labels.csv\"  # Replace with your dataset path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define the stage classification logic\n",
    "def classify_stage(row):\n",
    "    overlap = row[\"topics_overlap\"]\n",
    "    topic = row[\"topic_label\"]\n",
    "    sentiment = row[\"sentiment\"]\n",
    "    emotional_tone = row[\"final_consolidated_emotional_tone\"]\n",
    "\n",
    "    if overlap >= 0.2:\n",
    "        return \"Post-Purchase\"\n",
    "    if 0.1 <= overlap < 0.2:\n",
    "        if topic in [\"Connectivity & Portability\", \"Quality & Reviews\"]:\n",
    "            return \"Consideration\"\n",
    "        if topic in [\"Performance & Specifications\", \"Quality & Reviews\"]:\n",
    "            return \"Decision\"\n",
    "    if overlap < 0.1:\n",
    "        if topic in [\"Design & Usability\", \"Protection & Packaging\"]:\n",
    "            return \"Awareness\"\n",
    "        if topic in [\"Performance & Specifications\", \"Quality & Reviews\"]:\n",
    "            return \"Decision\"\n",
    "\n",
    "    if emotional_tone == \"Positive\" and sentiment == \"Positive\":\n",
    "        return \"Post-Purchase\"\n",
    "    elif emotional_tone == \"Neutral\" or sentiment == \"Neutral\":\n",
    "        return \"Consideration\"\n",
    "    elif emotional_tone == \"Negative\" or sentiment == \"Negative\":\n",
    "        return \"Decision\"\n",
    "    elif emotional_tone == \"Mixed\":\n",
    "        return \"Awareness\"\n",
    "\n",
    "    return \"Awareness\"\n",
    "\n",
    "# Apply classification logic\n",
    "df[\"stage\"] = df.apply(classify_stage, axis=1)\n",
    "\n",
    "# Map labels to numerical values\n",
    "label_map = {label: i for i, label in enumerate(df[\"stage\"].unique())}\n",
    "print(\"Label Map:\", label_map)\n",
    "\n",
    "# Split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"processed_text\"], df[\"stage\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert labels to numerical values\n",
    "train_labels = train_labels.map(label_map)\n",
    "val_labels = val_labels.map(label_map)\n",
    "\n",
    "# Load tokenizer and model\n",
    "model_name = \"meta-llama/Llama-3.2-3B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Add a padding token if missing\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    print(\"Added padding token '[PAD]' to tokenizer.\")\n",
    "\n",
    "# Load model and resize token embeddings\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=len(label_map)\n",
    ").to(device)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Set `pad_token_id` in the model's configuration\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Preprocess data\n",
    "def preprocess_data(texts, labels, tokenizer, max_length=256):\n",
    "    labels = labels.tolist()  # Ensure labels are a list\n",
    "    encodings = tokenizer(\n",
    "        list(texts),\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\": encodings[\"input_ids\"],\n",
    "        \"attention_mask\": encodings[\"attention_mask\"],\n",
    "        \"labels\": torch.tensor(labels, dtype=torch.long),\n",
    "    }\n",
    "\n",
    "train_data = preprocess_data(train_texts, train_labels, tokenizer)\n",
    "val_data = preprocess_data(val_texts, val_labels, tokenizer)\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "val_dataset = Dataset.from_dict(val_data)\n",
    "\n",
    "# Define evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"weighted\"),\n",
    "        \"precision\": precision_score(labels, preds, average=\"weighted\"),\n",
    "        \"recall\": recall_score(labels, preds, average=\"weighted\"),\n",
    "    }\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=1,  # Set batch size to 1 to avoid issues\n",
    "    per_device_eval_batch_size=1,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    logging_dir=\"./logs\",\n",
    "    learning_rate=2e-5,\n",
    "    report_to=\"none\",\n",
    "    fp16=False,  # Avoid mixed precision for simplicity\n",
    ")\n",
    "\n",
    "# Define Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "metrics = trainer.evaluate()\n",
    "print(\"Evaluation Metrics:\", metrics)\n",
    "\n",
    "# Analyze performance for a specific class (e.g., 'Awareness')\n",
    "y_true = val_labels.tolist()\n",
    "y_pred = trainer.predict(val_dataset).predictions.argmax(-1)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=label_map.keys()))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=label_map.keys(), yticklabels=label_map.keys())\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1512312c-6249-4607-a028-a1eac6d9b978",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Map: {'Decision': 0, 'Post-Purchase': 1, 'Awareness': 2, 'Consideration': 3}\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Decision       0.93      0.97      0.95        70\n",
      "Post-Purchase       0.75      0.43      0.55        28\n",
      "    Awareness       0.82      1.00      0.90        55\n",
      "Consideration       0.00      0.00      0.00         3\n",
      "\n",
      "     accuracy                           0.87       156\n",
      "    macro avg       0.63      0.60      0.60       156\n",
      " weighted avg       0.84      0.87      0.84       156\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[68  1  1  0]\n",
      " [ 5 12 11  0]\n",
      " [ 0  0 55  0]\n",
      " [ 0  3  0  0]]\n",
      "\n",
      "Overall Metrics:\n",
      "Accuracy: 0.87\n",
      "Precision: 0.84\n",
      "Recall: 0.87\n",
      "F1-Score: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"dataset_with_topic_labels.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Classification logic\n",
    "def classify_stage(row):\n",
    "    overlap = row[\"topics_overlap\"]\n",
    "    topic = row[\"topic_label\"]\n",
    "    sentiment = row[\"sentiment\"]\n",
    "    emotional_tone = row[\"final_consolidated_emotional_tone\"]\n",
    "\n",
    "    if overlap >= 0.2:\n",
    "        return \"Post-Purchase\"\n",
    "    if 0.1 <= overlap < 0.2:\n",
    "        if topic in [\"Connectivity & Portability\", \"Quality & Reviews\"]:\n",
    "            return \"Consideration\"\n",
    "        if topic in [\"Performance & Specifications\", \"Quality & Reviews\"]:\n",
    "            return \"Decision\"\n",
    "    if overlap < 0.1:\n",
    "        if topic in [\"Design & Usability\", \"Protection & Packaging\"]:\n",
    "            return \"Awareness\"\n",
    "        if topic in [\"Performance & Specifications\", \"Quality & Reviews\"]:\n",
    "            return \"Decision\"\n",
    "\n",
    "    if emotional_tone == \"Positive\" and sentiment == \"Positive\":\n",
    "        return \"Post-Purchase\"\n",
    "    elif emotional_tone == \"Neutral\" or sentiment == \"Neutral\":\n",
    "        return \"Consideration\"\n",
    "    elif emotional_tone == \"Negative\" or sentiment == \"Negative\":\n",
    "        return \"Decision\"\n",
    "    elif emotional_tone == \"Mixed\":\n",
    "        return \"Awareness\"\n",
    "\n",
    "    return \"Awareness\"\n",
    "\n",
    "# Apply classify_stage\n",
    "df[\"stage\"] = df.apply(classify_stage, axis=1)\n",
    "\n",
    "# Create label map\n",
    "label_map = {label: i for i, label in enumerate(df[\"stage\"].unique())}\n",
    "print(\"Label Map:\", label_map)\n",
    "\n",
    "# Convert labels to numeric\n",
    "df[\"stage_label\"] = df[\"stage\"].map(label_map)\n",
    "\n",
    "# Split data\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"processed_text\"], df[\"stage_label\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Text vectorization using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(train_texts)\n",
    "X_val = vectorizer.transform(val_texts)\n",
    "\n",
    "# Train Logistic Regression Classifier\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train, train_labels)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = lr_model.predict(X_val)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(val_labels, y_pred, target_names=label_map.keys()))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(val_labels, y_pred))\n",
    "\n",
    "# Overall metrics\n",
    "overall_accuracy = accuracy_score(val_labels, y_pred)\n",
    "overall_precision = precision_score(val_labels, y_pred, average=\"weighted\")\n",
    "overall_recall = recall_score(val_labels, y_pred, average=\"weighted\")\n",
    "overall_f1 = f1_score(val_labels, y_pred, average=\"weighted\")\n",
    "\n",
    "print(\"\\nOverall Metrics:\")\n",
    "print(f\"Accuracy: {overall_accuracy:.2f}\")\n",
    "print(f\"Precision: {overall_precision:.2f}\")\n",
    "print(f\"Recall: {overall_recall:.2f}\")\n",
    "print(f\"F1-Score: {overall_f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5c6f7e-2a66-4f73-b245-47d74c79e42b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.trainer because of the following error (look up to see its traceback):\nFailed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_utils because of the following error (look up to see its traceback):\noperator torchvision::nms does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/utils/import_utils.py:1793\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1792\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1793\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/modeling_utils.py:48\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftAdapterMixin, deepspeed_config, is_deepspeed_zero3_enabled\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LOSS_MAPPING\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     Conv1D,\n\u001b[1;32m     51\u001b[0m     apply_chunking_to_forward,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m     translate_to_torch_parallel_style,\n\u001b[1;32m     59\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/loss/loss_utils.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BCEWithLogitsLoss, MSELoss\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_deformable_detr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_for_object_detection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ForObjectDetectionLoss, ForSegmentationLoss\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/loss/loss_deformable_detr.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_transforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m center_to_corners_format\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_scipy_available\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/image_transforms.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     ChannelDimension,\n\u001b[1;32m     24\u001b[0m     ImageInput,\n\u001b[1;32m     25\u001b[0m     get_channel_dimension_axis,\n\u001b[1;32m     26\u001b[0m     get_image_size,\n\u001b[1;32m     27\u001b[0m     infer_channel_dimension_format,\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExplicitEnum, TensorType, is_jax_tensor, is_tf_tensor, is_torch_tensor\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/image_utils.py:59\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torchvision_available():\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InterpolationMode\n\u001b[1;32m     61\u001b[0m     pil_torch_interpolation_mapping \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     62\u001b[0m         PILImageResampling\u001b[38;5;241m.\u001b[39mNEAREST: InterpolationMode\u001b[38;5;241m.\u001b[39mNEAREST,\n\u001b[1;32m     63\u001b[0m         PILImageResampling\u001b[38;5;241m.\u001b[39mBOX: InterpolationMode\u001b[38;5;241m.\u001b[39mBOX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m         PILImageResampling\u001b[38;5;241m.\u001b[39mLANCZOS: InterpolationMode\u001b[38;5;241m.\u001b[39mLANCZOS,\n\u001b[1;32m     68\u001b[0m     }\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torchvision/__init__.py:10\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torchvision/_meta_registrations.py:163\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grad\u001b[38;5;241m.\u001b[39mnew_empty((batch_size, channels, height, width))\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mlibrary\u001b[38;5;241m.\u001b[39mregister_fake(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchvision::nms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmeta_nms\u001b[39m(dets, scores, iou_threshold):\n\u001b[1;32m    165\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_check(dets\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboxes should be a 2d tensor, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdets\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/library.py:795\u001b[0m, in \u001b[0;36mregister_fake.<locals>.register\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    794\u001b[0m     use_lib \u001b[38;5;241m=\u001b[39m lib\n\u001b[0;32m--> 795\u001b[0m use_lib\u001b[38;5;241m.\u001b[39m_register_fake(op_name, func, _stacklevel\u001b[38;5;241m=\u001b[39mstacklevel \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/library.py:184\u001b[0m, in \u001b[0;36mLibrary._register_fake\u001b[0;34m(self, op_name, fn, _stacklevel)\u001b[0m\n\u001b[1;32m    182\u001b[0m     func_to_register \u001b[38;5;241m=\u001b[39m fn\n\u001b[0;32m--> 184\u001b[0m handle \u001b[38;5;241m=\u001b[39m entry\u001b[38;5;241m.\u001b[39mfake_impl\u001b[38;5;241m.\u001b[39mregister(func_to_register, source)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registration_handles\u001b[38;5;241m.\u001b[39mappend(handle)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/_library/fake_impl.py:31\u001b[0m, in \u001b[0;36mFakeImplHolder.register\u001b[0;34m(self, func, source)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_fake(...): the operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqualname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malready has an fake impl registered at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m     )\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_dispatch_has_kernel_for_dispatch_key(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqualname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMeta\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_fake(...): the operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqualname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malready has an DispatchKey::Meta implementation via a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_fake.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: operator torchvision::nms does not exist",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/utils/import_utils.py:1793\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1792\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1793\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/integrations/integration_utils.py:36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel, TFPreTrainedModel\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m version\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/utils/import_utils.py:1781\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1781\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m   1782\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/utils/import_utils.py:1795\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1795\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1796\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1797\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1798\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.modeling_utils because of the following error (look up to see its traceback):\noperator torchvision::nms does not exist",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/utils/import_utils.py:1793\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1792\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1793\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:42\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Integrations must be imported before ML frameworks:\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     43\u001b[0m     get_reporting_integration_callbacks,\n\u001b[1;32m     44\u001b[0m     hp_params,\n\u001b[1;32m     45\u001b[0m )\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# isort: on\u001b[39;00m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/utils/import_utils.py:1781\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1781\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m   1782\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/utils/import_utils.py:1795\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1795\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1796\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1797\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1798\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_utils because of the following error (look up to see its traceback):\noperator torchvision::nms does not exist",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/utils/import_utils.py:1781\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1779\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1781\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m   1782\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/utils/import_utils.py:1795\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1793\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1795\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1796\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1797\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1798\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.trainer because of the following error (look up to see its traceback):\nFailed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_utils because of the following error (look up to see its traceback):\noperator torchvision::nms does not exist"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensure correct device usage\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"dataset_with_topic_labels.csv\"  # Replace with your dataset path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define the stage classification logic\n",
    "def classify_stage(row):\n",
    "    overlap = row[\"topics_overlap\"]\n",
    "    topic = row[\"topic_label\"]\n",
    "    sentiment = row[\"sentiment\"]\n",
    "    emotional_tone = row[\"final_consolidated_emotional_tone\"]\n",
    "\n",
    "    if overlap >= 0.2:\n",
    "        return \"Post-Purchase\"\n",
    "    if 0.1 <= overlap < 0.2:\n",
    "        if topic in [\"Connectivity & Portability\", \"Quality & Reviews\"]:\n",
    "            return \"Consideration\"\n",
    "        if topic in [\"Performance & Specifications\", \"Quality & Reviews\"]:\n",
    "            return \"Decision\"\n",
    "    if overlap < 0.1:\n",
    "        if topic in [\"Design & Usability\", \"Protection & Packaging\"]:\n",
    "            return \"Awareness\"\n",
    "        if topic in [\"Performance & Specifications\", \"Quality & Reviews\"]:\n",
    "            return \"Decision\"\n",
    "\n",
    "    if emotional_tone == \"Positive\" and sentiment == \"Positive\":\n",
    "        return \"Post-Purchase\"\n",
    "    elif emotional_tone == \"Neutral\" or sentiment == \"Neutral\":\n",
    "        return \"Consideration\"\n",
    "    elif emotional_tone == \"Negative\" or sentiment == \"Negative\":\n",
    "        return \"Decision\"\n",
    "    elif emotional_tone == \"Mixed\":\n",
    "        return \"Awareness\"\n",
    "\n",
    "    return \"Awareness\"\n",
    "\n",
    "# Apply classification logic\n",
    "df[\"stage\"] = df.apply(classify_stage, axis=1)\n",
    "\n",
    "# Map labels to numerical values\n",
    "label_map = {label: i for i, label in enumerate(df[\"stage\"].unique())}\n",
    "print(\"Label Map:\", label_map)\n",
    "\n",
    "# Split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"processed_text\"], df[\"stage\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert labels to numerical values\n",
    "train_labels = train_labels.map(label_map)\n",
    "val_labels = val_labels.map(label_map)\n",
    "\n",
    "# Load tokenizer and model\n",
    "model_name = \"meta-llama/Llama-3.2-3B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Add a padding token if missing\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    print(\"Added padding token '[PAD]' to tokenizer.\")\n",
    "\n",
    "# Load model and resize token embeddings\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=len(label_map)\n",
    ").to(device)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Set `pad_token_id` in the model's configuration\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Preprocess data\n",
    "def preprocess_data(texts, labels, tokenizer, max_length=256):\n",
    "    labels = labels.tolist()  # Ensure labels are a list\n",
    "    encodings = tokenizer(\n",
    "        list(texts),\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\": encodings[\"input_ids\"],\n",
    "        \"attention_mask\": encodings[\"attention_mask\"],\n",
    "        \"labels\": torch.tensor(labels, dtype=torch.long),\n",
    "    }\n",
    "\n",
    "train_data = preprocess_data(train_texts, train_labels, tokenizer)\n",
    "val_data = preprocess_data(val_texts, val_labels, tokenizer)\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "val_dataset = Dataset.from_dict(val_data)\n",
    "\n",
    "# Define evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"weighted\"),\n",
    "        \"precision\": precision_score(labels, preds, average=\"weighted\"),\n",
    "        \"recall\": recall_score(labels, preds, average=\"weighted\"),\n",
    "    }\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=1,  # Set batch size to 1 to avoid issues\n",
    "    per_device_eval_batch_size=1,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    logging_dir=\"./logs\",\n",
    "    learning_rate=2e-5,\n",
    "    report_to=\"none\",\n",
    "    fp16=False,  # Avoid mixed precision for simplicity\n",
    ")\n",
    "\n",
    "# Define Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "metrics = trainer.evaluate()\n",
    "print(\"Evaluation Metrics:\", metrics)\n",
    "\n",
    "# Analyze performance for a specific class (e.g., 'Awareness')\n",
    "y_true = val_labels.tolist()\n",
    "y_pred = trainer.predict(val_dataset).predictions.argmax(-1)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=label_map.keys()))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=label_map.keys(), yticklabels=label_map.keys())\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38d0ea4-a182-47c0-841c-612b35a19f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eb47e0-b24d-410b-bbc5-841e0ca01044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ec1bef-080f-4ccc-8c2f-5c97d995a350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f72c61-f668-4c8e-a53c-9831a7d9da6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd184b9-3d64-4cc0-801d-b85c6b400a31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
